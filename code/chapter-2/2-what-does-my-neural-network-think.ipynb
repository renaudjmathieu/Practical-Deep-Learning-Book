{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-2/2-what-does-my-neural-network-think.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "This code is part of [Chapter 2 - What’s in the Picture: Image Classification with Keras](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch02.html). This notebook will not run on Colab. For Colab, use <a target=\"_blank\" href=\"https://github.com/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-2/2-colab-what-does-my-neural-network-think.ipynb\">chapter-2/2-colab-what-does-my-neural-network-think.ipynb</a> instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Does My Neural Network Think?\n",
    "\n",
    "In this code sample, we try to understand why the neural network made a particular prediction. We use visualization (a heatmap) to understand the decision-making that is going on within the network. Using color, we visually identify the areas within an image that prompted a decision. “Hot” spots, represented by warmer colors (red, orange, and yellow) highlight the areas with the maximum signal, whereas cooler colors (blue, purple) indicate low signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visualization.py` script produces the heatmap for one or more input images, overlays it on the image, and stitches it side-by-side with the original image for comparison. The script accepts arguments for image path or a directory that contains frames of a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Heatmap of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "2022-11-22 03:22:41.984092: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-22 03:22:41.984234: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python visualization.py --process image --path ../../sample-images/dog.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](./data/dog-output.jpg)\n",
    "The right half of the image indicates the “areas of heat” along with the correct prediction of a 'Cardigan Welsh Corgi'.\n",
    "\n",
    "Note: As we can see below, the label is different from the labels shown in the book. This is because we use the [VGG-19](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) model in the visualization script, whereas we used the [ResNet-50](https://github.com/KaimingHe/deep-residual-networks) model in the book.\n",
    "\n",
    "![t](./data/cat-output.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Heatmap of a Video\n",
    "\n",
    "Before we can run the `visualization.py` script, we will need to use `ffmpeg` to split up a video into individual frames. Let's create a directory to store these frames and pass its name as an argument into the `ffmpeg` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data/kitchen: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/kitchen-input.mov':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "    com.apple.quicktime.location.ISO6709: +37.4042-122.0350+008.573/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone X\n",
      "    com.apple.quicktime.software: 11.3\n",
      "    com.apple.quicktime.creationdate: 2018-04-28T22:30:30-0700\n",
      "  Duration: 00:00:13.63, start: 0.000000, bitrate: 15330 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, 15224 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : H.264\n",
      "    Side data:\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 92 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x120b88000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138d78000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138d88000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138d98000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138da8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138db8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138dc8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138dd8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138de8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138df8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[1;34m[swscaler @ 0x138e08000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140008000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140018000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140028000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140038000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140048000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140058000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140068000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140078000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140088000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x140098000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x150018000] \u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120b88000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120b98000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120ba8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120bb8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120bc8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x138e08000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x138d78000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x138d88000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x148108000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x1400a8000] \u001b[0m\u001b[1;34m[swscaler @ 0x148118000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x112098000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120a8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x110188000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x110198000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1101a8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1101b8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120b8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120c8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120d8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120e8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;34m[swscaler @ 0x120bd8000] \u001b[0m\u001b[1;34m[swscaler @ 0x1120f8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, image2, to 'data/kitchen/thumb%04d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2018-04-28T22:30:30-0700\n",
      "    com.apple.quicktime.location.ISO6709: +37.4042-122.0350+008.573/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone X\n",
      "    com.apple.quicktime.software: 11.3\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: mjpeg, yuvj420p(pc, bt709, progressive), 1080x1920, q=2-31, 200 kb/s, 25 fps, 25 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-04-29T05:30:31.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.37.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "      displaymatrix: rotation of -0.00 degrees\n",
      "frame=  341 fps=126 q=24.8 Lsize=N/A time=00:00:13.64 bitrate=N/A speed=5.03x    \n",
      "video:17019kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i data/kitchen-input.mov -vf fps=25 data/kitchen/thumb%04d.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the `visualization.py` script with the path of the directory containing the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "2022-11-22 03:23:16.267276: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-22 03:23:16.267401: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "!python visualization.py --process video --path data/kitchen/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile a video from those frames using ffmpeg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with Apple clang version 14.0.0 (clang-1400.0.29.102)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.1.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, image2, from 'data/kitchen_output/result-%04d.jpg':\n",
      "  Duration: 00:00:13.64, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1080x1920 [SAR 1:1 DAR 9:16], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0musing cpu capabilities: ARMv8 NEON\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'kitchen-output.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1080x1920 [SAR 1:1 DAR 9:16], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  341 fps= 55 q=-1.0 Lsize=   15457kB time=00:00:13.52 bitrate=9365.4kbits/s speed= 2.2x     \n",
      "video:15452kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.029988%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mframe I:10    Avg QP:21.27  size: 54544\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mframe P:131   Avg QP:23.65  size: 46756\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mframe B:200   Avg QP:24.47  size: 45759\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mconsecutive B-frames: 17.6% 10.0%  7.9% 64.5%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mmb I  I16..4: 34.4% 65.1%  0.5%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mmb P  I16..4: 32.8% 61.8%  0.5%  P16..4:  2.5%  1.4%  0.7%  0.0%  0.0%    skip: 0.4%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mmb B  I16..4: 19.6% 44.4%  0.3%  B16..8: 11.3%  6.2%  1.9%  direct: 8.0%  skip: 8.3%  L0:46.9% L1:40.7% BI:12.4%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0m8x8 transform intra:67.0% inter:83.5%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mcoded y,uvDC,uvAC intra: 43.6% 72.7% 4.0% inter: 36.3% 63.8% 1.3%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mi16 v,h,dc,p: 47% 29% 13% 10%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 24% 38%  2%  1%  1%  1%  1%  3%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 22% 16%  3%  6%  5%  5%  2%  3%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mi8c dc,h,v,p: 34% 25% 30% 11%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mWeighted P-Frames: Y:18.3% UV:14.5%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mref P L0: 49.5% 13.8% 22.3% 13.6%  0.8%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mref B L0: 77.2% 17.8%  5.0%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mref B L1: 90.3%  9.7%\n",
      "\u001b[1;36m[libx264 @ 0x142e07d40] \u001b[0mkb/s:9279.92\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -framerate 25 -i data/kitchen_output/result-%04d.jpg kitchen-output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Heatmap Demo Video](./data/kitchen-output/result_0001.jpg)](https://youtu.be/DhMzvbYjkUY \"Chapter 2 - Heatmap Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Imagine generating heatmaps to analyze the strong points and shortfalls of your trained model or a pretrained model. Don't forget to post your videos on Twitter with the hashtag [#PracticalDL](https://twitter.com/hashtag/PracticalDL)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
